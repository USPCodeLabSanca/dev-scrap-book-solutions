{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the chapter 4 of \"Web Scraping with Python\" you were able to learn more about the following subjects:\n",
    "* Planning and Defining Objects\n",
    "* Handling with different layouts\n",
    "* Tracking through search\n",
    "* Tracking through links\n",
    "* Defining site through different mechanisms\n",
    "\n",
    "The following cells aim to practice the contents listed above. For any sugestions, contact *gabriel.vasconcelos@usp.br*\n",
    "\n",
    "Use the website https://faithful-ray-costume.cyclic.app/ and other sites requested to answer this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup and other libraries you find useful\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "Build a flexible crawler based on search method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content:\n",
    "    def __init__(self, title, author, price, cover):\n",
    "        self.title = title\n",
    "        self.author = author\n",
    "        self.price = price\n",
    "        self.cover = cover\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'''==== Book ====\n",
    "        Title: {self.title}\n",
    "        Author: {self.author}\n",
    "        Price: {self.price}\n",
    "        Cover: {self.cover}\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    def __init__(self, name, url, searchUrl, resultListing,\n",
    "                 resultUrl, absoluteUrl, titleTag, authorTag,\n",
    "                 priceTag, coverTag):\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.searchUrl = searchUrl\n",
    "        self.resultListing = resultListing\n",
    "        self.resultUrl = resultUrl\n",
    "        self.absoluteUrl = absoluteUrl\n",
    "        self.titleTag = titleTag\n",
    "        self.authorTag = authorTag\n",
    "        self.priceTag = priceTag\n",
    "        self.coverTag = coverTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    def getPage(self, url):\n",
    "        try:\n",
    "            req = requests.get(url)\n",
    "        except requests.exceptions.RequestException:\n",
    "            print(\"It wasn`t possible to access this URL\")\n",
    "            return None\n",
    "        return BeautifulSoup(req.text, 'html.parser')\n",
    "    \n",
    "    def safeGet(self, pageObj, selector):\n",
    "        childObj = pageObj.select(selector)\n",
    "        if childObj is not None and len(childObj) > 0:\n",
    "            if childObj[0].name == 'img':\n",
    "                return childObj[0].attrs['src']\n",
    "            return childObj[0].get_text()\n",
    "        return \"\"\n",
    "    \n",
    "    def search(self, topic, site: Website):\n",
    "        bs = self.getPage(site.searchUrl + topic)\n",
    "        searchResults = bs.select(site.resultListing)\n",
    "        for result in searchResults[0].find_all(site.resultUrl, recursive=False):\n",
    "            try:\n",
    "                url = result.attrs[\"href\"]\n",
    "            except AttributeError:\n",
    "                print(\"URL not found in crawler\")\n",
    "                return None\n",
    "            if (site.absoluteUrl):\n",
    "                bs = self.getPage(url)\n",
    "            else:\n",
    "                bs = self.getPage(site.url + url)\n",
    "            if bs is None:\n",
    "                print(\"Something was wrong with that page or URL. Skipping!\")\n",
    "                return\n",
    "            title = self.safeGet(bs, site.titleTag)\n",
    "            author = self.safeGet(bs, site.authorTag)\n",
    "            price = self.safeGet(bs, site.priceTag)\n",
    "            cover = self.safeGet(bs, site.coverTag)\n",
    "            content = Content(title, author, price, cover)\n",
    "            print(content)\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "\n",
    "Test it against these websites:\n",
    "* https://scraping-cap4.herokuapp.com/\n",
    "* https://www.amazon.com.br/\n",
    "* https://www3.livrariacultura.com.br/\n",
    "\n",
    "Obtain the following data:\n",
    "* Book title\n",
    "* Book author\n",
    "* Book price\n",
    "* Book cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def soma(a, b):\n",
    "    return a + b\n",
    "\n",
    "soma(*[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Book ====\n",
      "        Title: Estatística básica\n",
      "        Author: Pedro A. Morettin\n",
      "        Price: R$ 104,90\n",
      "        Cover: https://m.media-amazon.com/images/I/41pOrXotc-L._SY344_BO1,204,203,200_QL70_ML2_.jpg\n",
      "        \n",
      "==== Book ====\n",
      "        Title: Data Science Do Zero: Noções Fundamentais com Python\n",
      "        Author: Joel Grus\n",
      "        Price: R$ 59,90\n",
      "        Cover: https://m.media-amazon.com/images/I/51psvxQpAbS._SY344_BO1,204,203,200_QL70_ML2_.jpg\n",
      "        \n",
      "==== Book ====\n",
      "        Title: Web Scraping com Python: Coletando Mais Dados da web Moderna\n",
      "        Author: Ryan Mitchell\n",
      "        Price: R$ 72,17\n",
      "        Cover: https://m.media-amazon.com/images/I/41gx74x+gdL._SY344_BO1,204,203,200_.jpg\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Code below\n",
    "\n",
    "crawler = Crawler()\n",
    "\n",
    "siteData = [\n",
    "    ['Livraria', 'https://faithful-ray-costume.cyclic.app', 'https://faithful-ray-costume.cyclic.app/?search=',\n",
    "     '.book-list', 'a', False, '.book-div h1', '.book-title span', '.basic b span', 'img']\n",
    "]\n",
    "\n",
    "sites = [Website(*site) for site in siteData]\n",
    "\n",
    "topics = ['estat', 'python']\n",
    "\n",
    "for site in sites:\n",
    "    for topic in topics:\n",
    "        crawler.search(topic, site)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7f22e608a9410c9a00adbb49e3cb6a72010c497ae6b30c9496ff58de178a89c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
